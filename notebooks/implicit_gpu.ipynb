{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3zh-ShVdzDHQ"
   },
   "source": [
    "# Why Implicit ratings?\n",
    "\n",
    "Explicit recommenders tend to focus on the gathered information – those user-item pairs that we know their ratings – which provide a balanced picture on the user preference. Thus, the remaining useritem relationships, which typically constitute the vast majority of the data, are treated as “missing data” and are omitted from the analysis. This is impossible with implicit feedback, as concentrating only on the gathered feedback will leave us with the positive feedback, greatly misrepresenting the full user profile. Hence, it is crucial to address also the missing data, which is where most negative feedback is expected to be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZf56wGkC3yJ"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "iszyGF1kDpo-"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import preprocess\n",
    "import utils\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(16, 8), max_open_warning=False)\n",
    "from surprise import SVD, SVDpp, NMF\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "import codecs\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_implicit_data(debug=False, datadir='../dblp-ref'):\n",
    "    # Note that this is not train-test split. This is just entire data. \n",
    "    # (skipping papers which have 0 citation)\n",
    "    if debug:\n",
    "        DBLP_LIST = [ datadir+'/dblp-ref-3.json' ]\n",
    "        saveFilename = 'aminer-debug.tsv'\n",
    "    else:\n",
    "        DBLP_LIST = [ datadir+'/dblp-ref-0.json',\n",
    "        datadir+'/dblp-ref-1.json',\n",
    "        datadir+'/dblp-ref-2.json',\n",
    "        datadir+'/dblp-ref-3.json' ]\n",
    "        saveFilename = 'aminer-full.tsv'\n",
    "        \n",
    "    with codecs.open(datadir+'/'+saveFilename, \"w\", \"utf8\") as o:\n",
    "        for each_file in DBLP_LIST:\n",
    "            with open(each_file) as f:\n",
    "                line = f.readline()\n",
    "                while line:\n",
    "                    data = json.loads(line)\n",
    "                    try:\n",
    "                        for ref in data[\"references\"]:\n",
    "                            o.write(\"%s\\t%s\\t%s\\n\" % (data[\"id\"], ref, 1))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_implicit_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_implicit_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMD4xu3iOGPL"
   },
   "source": [
    "# Implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eg83S9c8af3X"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import codecs\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.approximate_als import (AnnoyAlternatingLeastSquares, FaissAlternatingLeastSquares,\n",
    "                                      NMSLibAlternatingLeastSquares)\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight)\n",
    "\n",
    "# maps command line model argument to class name\n",
    "MODELS = {\"als\":  AlternatingLeastSquares,\n",
    "          \"nmslib_als\": NMSLibAlternatingLeastSquares,\n",
    "          \"annoy_als\": AnnoyAlternatingLeastSquares,\n",
    "          \"faiss_als\": FaissAlternatingLeastSquares,\n",
    "          \"tfidf\": TFIDFRecommender,\n",
    "          \"cosine\": CosineRecommender,\n",
    "          \"bpr\": BayesianPersonalizedRanking,\n",
    "          \"bm25\": BM25Recommender}\n",
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "    model_class = MODELS.get(model_name)\n",
    "    if not model_class:\n",
    "        raise ValueError(\"Unknown Model '%s'\" % model_name)\n",
    "\n",
    "    # some default params\n",
    "    if issubclass(model_class, AlternatingLeastSquares):\n",
    "        params = {'factors': 64, 'dtype': numpy.float32, 'use_gpu': False}\n",
    "    elif model_name == \"bm25\":\n",
    "        params = {'K1': 100, 'B': 0.5}\n",
    "    elif model_name == \"bpr\":\n",
    "        params = {'factors': 63, 'use_gpu': False}\n",
    "    else:\n",
    "        params = {}\n",
    "\n",
    "    return model_class(**params)\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\" Reads in the AMINER dataset, and returns a tuple of a pandas dataframe\n",
    "    and a sparse matrix of artist/user/playcount \"\"\"\n",
    "    # read in triples of user/artist/playcount from the input dataset\n",
    "    # get a model based off the input params\n",
    "    start = time.time()\n",
    "    print(\"reading data from %s\"% (filename))\n",
    "    data = pandas.read_table(filename,\n",
    "                             usecols=[0, 1, 2],\n",
    "                             names=['user', 'ref', 'cites'],\n",
    "                             na_filter=False)\n",
    "\n",
    "    # map each artist and user to a unique numeric value\n",
    "    data['user'] = data['user'].astype(\"category\")\n",
    "    data['ref'] = data['ref'].astype(\"category\")\n",
    "\n",
    "    # create a sparse matrix of all the users/plays\n",
    "    cites = coo_matrix((data['cites'].astype(numpy.float32),\n",
    "                       (data['ref'].cat.codes.copy(),\n",
    "                        data['user'].cat.codes.copy())))\n",
    "\n",
    "    print(\"read data file in {}\".format( time.time() - start))\n",
    "    return data, cites\n",
    "\n",
    "'''\n",
    "def calculate_similar_artists(input_filename, output_filename, model_name=\"als\"):\n",
    "    \"\"\" generates a list of similar artists in lastfm by utiliizing the 'similar_items'\n",
    "    api of the models \"\"\"\n",
    "    df, plays = read_data(input_filename)\n",
    "\n",
    "    # create a model from the input data\n",
    "    model = get_model(model_name)\n",
    "\n",
    "    # if we're training an ALS based model, weight input for last.fm\n",
    "    # by bm25\n",
    "    if issubclass(model.__class__, AlternatingLeastSquares):\n",
    "        # lets weight these models by bm25weight.\n",
    "        print(\"weighting matrix by bm25_weight\")\n",
    "        plays = bm25_weight(plays, K1=100, B=0.8)\n",
    "\n",
    "        # also disable building approximate recommend index\n",
    "        model.approximate_recommend = False\n",
    "\n",
    "    # this is actually disturbingly expensive:\n",
    "    plays = plays.tocsr()\n",
    "\n",
    "    print(\"training model {}\".format( model_name))\n",
    "    start = time.time()\n",
    "    model.fit(plays)\n",
    "    print(\"trained model '%s' in %0.2f\"%( model_name, time.time() - start))\n",
    "\n",
    "    # write out similar artists by popularity\n",
    "    artists = dict(enumerate(df['artist'].cat.categories))\n",
    "    start = time.time()\n",
    "    print(\"calculating top artists\")\n",
    "    user_count = df.groupby('artist').size()\n",
    "    to_generate = sorted(list(artists), key=lambda x: -user_count[x])\n",
    "\n",
    "    # write out as a TSV of artistid, otherartistid, score\n",
    "    with codecs.open(output_filename, \"w\", \"utf8\") as o:\n",
    "        for artistid in to_generate:\n",
    "            artist = artists[artistid]\n",
    "            for other, score in model.similar_items(artistid, 11):\n",
    "                o.write(\"%s\\t%s\\t%s\\n\" % (artist, artists[other], score))\n",
    "\n",
    "    print(\"generated similar artists in %0.2f\"%(time.time() - start))\n",
    "'''\n",
    "\n",
    "def calculate_recommendations(input_filename, output_filename, model_name=\"als\"):\n",
    "    \"\"\" Generates artist recommendations for each user in the dataset \"\"\"\n",
    "    # train the model based off input params\n",
    "    df, cites = read_data(input_filename)\n",
    "\n",
    "    # create a model from the input data\n",
    "    model = get_model(model_name)\n",
    "\n",
    "    # if we're training an ALS based model, weight input for last.fm\n",
    "    # by bm25\n",
    "    if issubclass(model.__class__, AlternatingLeastSquares):\n",
    "        # lets weight these models by bm25weight.\n",
    "        print(\"weighting matrix by bm25_weight\")\n",
    "        cites = bm25_weight(cites, K1=100, B=0.8)\n",
    "\n",
    "        # also disable building approximate recommend index\n",
    "        model.approximate_similar_items = False\n",
    "\n",
    "    # this is actually disturbingly expensive:\n",
    "    cites = cites.tocsr()\n",
    "\n",
    "    print(\"training model {}\".format(model_name))\n",
    "    start = time.time()\n",
    "    model.fit(cites)\n",
    "    print(\"trained model '%s' in %0.2f\"%( model_name, time.time() - start))\n",
    "\n",
    "    # generate recommendations for each user and write out to a file\n",
    "    artists = dict(enumerate(df['ref'].cat.categories))\n",
    "    start = time.time()\n",
    "    user_cites = cites.T.tocsr()\n",
    "    with codecs.open(output_filename, \"w\", \"utf8\") as o:\n",
    "        for userid, username in enumerate(df['user'].cat.categories):\n",
    "            for artistid, score in model.recommend(userid, user_cites):\n",
    "                o.write(\"%s\\t%s\\t%s\\n\" % (username, artists[artistid], score))\n",
    "    print(\"generated recommendations in %0.2f\"%(  time.time() - start))\n",
    "\n",
    "\n",
    "def start(inputfile='../dblp-ref/aminer-debug.tsv',outputfile='../output-debug.tsv', model='als'):\n",
    "\n",
    "    #if recommend:\n",
    "    calculate_recommendations(inputfile, outputfile, model_name=model)\n",
    "    #else:\n",
    "        #calculate_similar_artists(inputfile, outputfile, model_name=model)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 132,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 5
      }
     ]
    },
    "colab_type": "code",
    "id": "17w7vir8bVuL",
    "outputId": "c681084e-f36c-4101-d0d1-42f844bdd7ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from ../dblp-ref/aminer-debug.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data file in 1.4693903923034668\n",
      "weighting matrix by bm25_weight\n",
      "training model als\n",
      "trained model 'als' in 7.02\n",
      "generated recommendations in 385.65\n"
     ]
    }
   ],
   "source": [
    "!export OPENBLAS_NUM_THREADS=1\n",
    "!export MKL_NUM_THREADS=1\n",
    "\n",
    "start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "If we use threshold of 0.1, we generated a total of 18603 recommendations for 47018 papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "iK-gzIsXyQWj"
   },
   "outputs": [],
   "source": [
    "visData = pd.read_table('../output-debug.tsv',\n",
    "                             usecols=[0, 1, 2],\n",
    "                             names=['user', 'ref', 'score'],\n",
    "                             na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb11e730d30>]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7sAAAHiCAYAAAAphNvgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAKAdsQsAAEA7/x9DCrzL41rH+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb11e4962b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visData.hist(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.701800e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.636435e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.633586e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.102670e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.180060e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.240795e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.271420e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.139310e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "count  4.701800e+05\n",
       "mean   1.636435e-02\n",
       "std    3.633586e-02\n",
       "min    2.102670e-10\n",
       "25%    5.180060e-04\n",
       "50%    3.240795e-03\n",
       "75%    1.271420e-02\n",
       "max    7.139310e-01"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18603"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger_than_point_one = visData[visData[\"score\"]>0.1]\n",
    "len(bigger_than_point_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug_dict = preprocess.create_paper_paper_dict(datadir=\"../dblp-ref\",debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47018"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_0_or_more(data_dict):\n",
    "  # papers which cite 0 paper is useless. remove from data.\n",
    "    count0_list = []\n",
    "    for key, value in data_dict.items():\n",
    "        if len(value) == 0:\n",
    "            count0_list.append(key)\n",
    "    for each in count0_list:\n",
    "        del data_dict[each]\n",
    "    return count0_list, data_dict\n",
    "\n",
    "count0_list, rest_dict = filter_0_or_more(debug_dict)\n",
    "len(rest_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can use the entire training data by this:\n",
    "!export OPENBLAS_NUM_THREADS=1\n",
    "!export MKL_NUM_THREADS=1\n",
    "start(inputfile='../dblp-ref/aminer-full.tsv',outputfile='../output-full.tsv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "implicit-gpu",
   "provenance": [
    {
     "file_id": "1pKI6tFJYzzEBmVLhgoX68hPBIq4ya_1I",
     "timestamp": 1522520520508
    },
    {
     "file_id": "1SRTLWrrMWplNQFy9oHIhM7XJJFtv9xCP",
     "timestamp": 1522338031582
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
