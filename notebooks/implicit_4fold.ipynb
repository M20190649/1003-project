{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3zh-ShVdzDHQ"
   },
   "source": [
    "# 4fold\n",
    "\n",
    "If you wish to use GPU, change 'gpu' and 'use_gpu' in get_model accordingly.\n",
    "\n",
    "if using faiss_als, make sure you have faiss installed. if annoy_als, annoy must be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZf56wGkC3yJ"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "iszyGF1kDpo-"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import preprocess\n",
    "import utils\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(16, 8), max_open_warning=False)\n",
    "from surprise import SVD, SVDpp, NMF\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "import codecs\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMD4xu3iOGPL"
   },
   "source": [
    "# Implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eg83S9c8af3X"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import codecs\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.approximate_als import (AnnoyAlternatingLeastSquares, FaissAlternatingLeastSquares,\n",
    "                                      NMSLibAlternatingLeastSquares)\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight)\n",
    "\n",
    "# maps command line model argument to class name\n",
    "MODELS = {\"als\":  AlternatingLeastSquares,\n",
    "          \"nmslib_als\": NMSLibAlternatingLeastSquares,\n",
    "          \"annoy_als\": AnnoyAlternatingLeastSquares,\n",
    "          \"faiss_als\": FaissAlternatingLeastSquares,\n",
    "          \"tfidf\": TFIDFRecommender,\n",
    "          \"cosine\": CosineRecommender,\n",
    "          \"bpr\": BayesianPersonalizedRanking,\n",
    "          \"bm25\": BM25Recommender}\n",
    "\n",
    "\n",
    "\n",
    "# NOT USING GPU?? CHANGE CODE HERE\n",
    "def get_model(model_name,k,lam):\n",
    "    model_class = MODELS.get(model_name)\n",
    "    if not model_class:\n",
    "        raise ValueError(\"Unknown Model '%s'\" % model_name)\n",
    "\n",
    "    # some default params\n",
    "    if model_name == \"faiss_als\":\n",
    "        params = {'factors': k, 'dtype': numpy.float32, 'use_gpu': False, \n",
    "                  'gpu': False,  # keyerror -1\n",
    "                  \"calculate_training_loss\": True, \"regularization\": lam, \"iterations\": 15}\n",
    "    elif issubclass(model_class, AlternatingLeastSquares):\n",
    "        params = {'factors': k, 'dtype': numpy.float32, 'use_gpu': False, \n",
    "                  #'gpu': True,  # keyerror -1\n",
    "                  \"calculate_training_loss\": True, \"regularization\": lam, \"iterations\": 15}\n",
    "    elif model_name == \"bm25\":\n",
    "        params = {'K1': 100, 'B': 0.5}\n",
    "    elif model_name == \"bpr\":\n",
    "        params = {'factors': 63, 'use_gpu': True}\n",
    "    else:\n",
    "        params = {}\n",
    "\n",
    "    return model_class(**params)\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\" Reads in the AMINER dataset, and returns a tuple of a pandas dataframe\n",
    "    and a sparse matrix of artist/user/playcount \"\"\"\n",
    "    # read in triples of user/artist/playcount from the input dataset\n",
    "    # get a model based off the input params\n",
    "    start = time.time()\n",
    "    print(\"reading data from %s\"% (filename))\n",
    "    data = pandas.read_table(filename,\n",
    "                             usecols=[0, 1, 2],\n",
    "                             names=['user', 'ref', 'cites'],\n",
    "                             na_filter=False)\n",
    "\n",
    "    # map each artist and user to a unique numeric value\n",
    "    data['user'] = data['user'].astype(\"category\")\n",
    "    data['ref'] = data['ref'].astype(\"category\")\n",
    "\n",
    "    # create a sparse matrix of all the users/plays\n",
    "    cites = coo_matrix((data['cites'].astype(numpy.float32),\n",
    "                       (data['ref'].cat.codes.copy(),\n",
    "                        data['user'].cat.codes.copy())))\n",
    "\n",
    "    print(\"read data file in {}\".format( time.time() - start))\n",
    "    return data, cites\n",
    "\n",
    "def calculate_recommendations(k, lam, input_filename, recommend_filename, similar_filename, model_name=\"als\"):\n",
    "    \"\"\" Generates artist recommendations for each user in the dataset \"\"\"\n",
    "    # train the model based off input params\n",
    "    df, cites = read_data(input_filename)\n",
    "\n",
    "    # create a model from the input data\n",
    "    model = get_model(model_name,k,lam) \n",
    "\n",
    "    # if we're training an ALS based model, weight input for last.fm\n",
    "    # by bm25\n",
    "    if issubclass(model.__class__, AlternatingLeastSquares):\n",
    "        # lets weight these models by bm25weight.\n",
    "        print(\"weighting matrix by bm25_weight\")\n",
    "        #cites = bm25_weight(cites, K1=100, B=0.8)\n",
    "\n",
    "        # also disable building approximate recommend index\n",
    "        model.approximate_similar_items = True\n",
    "\n",
    "    # this is actually disturbingly expensive:\n",
    "    cites = cites.tocsr()\n",
    "\n",
    "    print(\"training model {}\".format(model_name))\n",
    "    start = time.time()\n",
    "    model.fit(cites) \n",
    "    print(\"trained model '%s' in %0.2f\"%( model_name, time.time() - start))\n",
    "\n",
    "    # generate recommendations for each user and write out to a file\n",
    "    #'''\n",
    "    artists = dict(enumerate(df['ref'].cat.categories))\n",
    "    start = time.time()\n",
    "    user_cites = cites.T.tocsr()\n",
    "    with codecs.open(recommend_filename, \"w\", \"utf8\") as o:\n",
    "        for userid, username in enumerate(df['user'].cat.categories):\n",
    "            for artistid, score in model.recommend(userid, user_cites, N=50):\n",
    "                try:\n",
    "                    o.write(\"%s\\t%s\\t%s\\n\" % (username, artists[artistid], score))\n",
    "                except:\n",
    "                    print(\"artistid {} had an error\".format(artistid))\n",
    "                    print(artistid in artists)\n",
    "                    print(artistid in df['user'].cat.categories)\n",
    "    print(\"generated recommendations in %0.2f\"%(  time.time() - start))\n",
    "    #'''\n",
    "    \n",
    "    # write out similar papers being cited\n",
    "    start = time.time()\n",
    "    user_count = df.groupby('ref').size()\n",
    "    to_generate = list(artists)#sorted(list(artists), key=lambda x: -user_count[x])\n",
    "    \n",
    "\n",
    "    print(\"returning similar papers depending on being cited by which\")\n",
    "    # write out as a TSV of artistid, otherartistid, score\n",
    "    with codecs.open(similar_filename, \"w\", \"utf8\") as o:\n",
    "        for artistid in to_generate:\n",
    "            try:\n",
    "                artist = artists[artistid]\n",
    "            except:\n",
    "                print(\"artistid {} had an error\".format(artistid))\n",
    "            for other, score in model.similar_items(artistid, 20):\n",
    "                try:\n",
    "                    o.write(\"%s\\t%s\\t%s\\n\" % (artist, artists[other], score))\n",
    "                except:\n",
    "                    print(\"other {} had an error\".format(other))\n",
    "\n",
    "    print(\"generated similar artists in %0.2f\"%(time.time() - start))\n",
    "\n",
    "def start(k, lam, inputfile, outputfile, similarfile, model='faiss_als'):\n",
    "\n",
    "    #if recommend:\n",
    "    calculate_recommendations(k, lam, inputfile, outputfile, similarfile, model_name=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it on debug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.getLogger(\"implicit\").addHandler(logging.FileHandler('output.log', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.getLogger(\"implicit\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export OPENBLAS_NUM_THREADS=1\n",
    "!export MKL_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 132,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 5
      }
     ]
    },
    "colab_type": "code",
    "id": "17w7vir8bVuL",
    "outputId": "c681084e-f36c-4101-d0d1-42f844bdd7ef",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from ../dblp-ref/4fold/4fold_0_train.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n",
      "DEBUG:implicit:Calculated transpose in 0.011s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data file in 0.2200608253479004\n",
      "weighting matrix by bm25_weight\n",
      "training model als\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:implicit:initialize factors in 0.5974574089050293\n",
      "DEBUG:implicit:finished iteration 0 in 7.334s\n",
      "DEBUG:implicit:loss at iteration 0 is 3.146728589442508e-05\n",
      "DEBUG:implicit:finished iteration 1 in 6.744s\n",
      "DEBUG:implicit:loss at iteration 1 is 3.105418595739045e-05\n",
      "DEBUG:implicit:finished iteration 2 in 6.954s\n",
      "DEBUG:implicit:loss at iteration 2 is 3.0846502860846634e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bf13fac5c7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;34m\"../faiss_4fold_rank_{}_lam_{}_recommend.tsv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;34m\"../faiss_4fold_rank_{}_lam_{}_similar.tsv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       model='als') \n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-5780a52cf247>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(k, lam, inputfile, outputfile, similarfile, model)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m#if recommend:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mcalculate_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-5780a52cf247>\u001b[0m in \u001b[0;36mcalculate_recommendations\u001b[0;34m(k, lam, input_filename, recommend_filename, similar_filename, model_name)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training model {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trained model '%s' in %0.2f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/implicit/als.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, item_users)\u001b[0m\n\u001b[1;32m    144\u001b[0m                    num_threads=self.num_threads)\n\u001b[1;32m    145\u001b[0m             solver(Ciu, self.item_factors, self.user_factors, self.regularization,\n\u001b[0;32m--> 146\u001b[0;31m                    num_threads=self.num_threads)\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished iteration %i in %.3fs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lam = 0.1\n",
    "k = 100\n",
    "start(k, lam, '../dblp-ref/4fold/4fold_0_train.tsv', \n",
    "      \"../faiss_4fold_rank_{}_lam_{}_recommend.tsv\".format(k,lam), \n",
    "      \"../faiss_4fold_rank_{}_lam_{}_similar.tsv\".format(k,lam) , \n",
    "      model='als') # You can also choose 'faiss_als' which is best with gpu or 'annoy_als' with cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "implicit-gpu",
   "provenance": [
    {
     "file_id": "1pKI6tFJYzzEBmVLhgoX68hPBIq4ya_1I",
     "timestamp": 1522520520508
    },
    {
     "file_id": "1SRTLWrrMWplNQFy9oHIhM7XJJFtv9xCP",
     "timestamp": 1522338031582
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
