{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(16, 8), max_open_warning=False)\n",
    "\n",
    "from surprise import SVD, SVDpp, NMF\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydict = preprocess.create_paper_paper_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creat random subset of dictionary, where we only retain references to themselves\n",
    "random_dict = preprocess.create_random_subset_paper_paper_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbering, reverse = dict(), dict()\n",
    "current_id = 0\n",
    "\n",
    "for i in random_dict.keys():\n",
    "    numbering[i] = current_id\n",
    "    reverse[current_id] = i\n",
    "    current_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build paper-paper matrix to observe its sparsity\n",
    "papernum = len(random_dict.keys())\n",
    "papermat = sp.dok_matrix((papernum,papernum), dtype=np.int8)\n",
    "for paper_id, ref_ids in random_dict.items():\n",
    "    for ref in ref_ids:\n",
    "        papermat[numbering[paper_id], numbering[ref]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sparsity: \",100*papermat.count_nonzero()/papernum**2, \"%\")\n",
    "plt.spy(papermat, markersize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess.create_surprise_paper_paper_data(random_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split that data to train, test set and then do SVD\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "algo = SVD(biased=False)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu = algo.pu\n",
    "qi = algo.qi\n",
    "Abar = np.dot(pu, np.transpose(qi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "min_val, max_val = -3, 3\n",
    "pos = axes.matshow(Abar[0:30, 0:30], cmap=plt.cm.coolwarm)\n",
    "fig.colorbar(pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
